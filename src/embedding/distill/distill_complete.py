import json
import os
import time
import traceback
from typing import List, Dict
from tqdm import tqdm
from openai import OpenAI, OpenAIError
from dotenv import load_dotenv

from prompt import emd_stage1, emd_stage2
from src.embedding.distill.build_persona_db import PersonaRetriever

def load_jsonl(file_path: str) -> List[Dict]:
    """è¯»å–JSONLæ–‡ä»¶å¹¶è¿”å›æ–‡æ¡£åˆ—è¡¨"""
    docs = []
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    with open(file_path, "r", encoding="utf-8") as f:
        for line_num, line in enumerate(tqdm(f, desc="è¯»å–è¾“å…¥JSONL"), 1):
            line = line.strip()
            if not line:
                continue
            try:
                doc = json.loads(line)
                if not all(key in doc for key in ["id", "contents"]):
                    print(f"âš ï¸ è·³è¿‡ç¬¬{line_num}è¡Œ: ç¼ºå°‘id/contentså­—æ®µ")
                    continue
                docs.append(doc)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ è·³è¿‡ç¬¬{line_num}è¡Œ: JSONè§£æé”™è¯¯ - {str(e)[:50]}")

    print(f"âœ… æˆåŠŸè¯»å– {len(docs)} ä¸ªæœ‰æ•ˆæ–‡æ¡£")
    return docs[50010:50020]


def append_single_doc_to_jsonl(doc: Dict, file_path: str) -> None:
    """å•ä¸ªæ–‡æ¡£è¿½åŠ å†™å…¥JSONLæ–‡ä»¶ï¼ˆä¸æ“¦é™¤åŸæœ‰æ•°æ®ï¼‰"""
    with open(file_path, "a", encoding="utf-8") as f:
        json.dump(doc, f, ensure_ascii=False)
        f.write("\n")


def init_llm_client() -> OpenAI:
    """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
    load_dotenv()
    api_key = os.getenv("QWEN_API_KEY")
    base_url = os.getenv("QWEN_URL")

    if not api_key or not base_url:
        raise ValueError("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®QWEN_API_KEYå’ŒQWEN_URL")

    try:
        return OpenAI(api_key=api_key, base_url=base_url)
    except Exception as e:
        raise RuntimeError(f"âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}") from e


def process_single_doc(
        doc: Dict,
        llm_client: OpenAI,
        persona_retriever: PersonaRetriever
) -> Dict:
    """å¤„ç†å•ä¸ªæ–‡æ¡£ï¼Œä¿®å¤è§’è‰²æ£€ç´¢å’Œæ ¼å¼é”™è¯¯"""
    try:
        # 1. å®‰å…¨è·å–æ–‡æ¡£å†…å®¹ï¼ˆé˜²æ­¢contentsä¸ºç©ºæˆ–éå­—ç¬¦ä¸²ï¼‰
        doc_contents = str(doc.get("contents", "")).strip()
        if not doc_contents:
            raise ValueError("æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œæ— æ³•å¤„ç†")

        # 2. é¢„å¤„ç†æ–‡æ¡£
        passage = {
            "id": doc["id"],
            "contents": doc_contents
        }
        passage_str = json.dumps(passage, ensure_ascii=False)

        # 3. æ£€ç´¢å€™é€‰è§’è‰²ï¼ˆæ ¸å¿ƒä¿®å¤ï¼šéªŒè¯è¿”å›ç»“æœæ ¼å¼ï¼‰
        try:
            # é™åˆ¶query_texté•¿åº¦ï¼Œé¿å…è¶…é•¿æ–‡æœ¬å¯¼è‡´æ£€ç´¢é”™è¯¯
            query_text = doc_contents[:256] if len(doc_contents) > 256 else doc_contents
            candidates = persona_retriever.retrieve_similar_personas(
                query_text=query_text,  # ç¡®ä¿ä¼ å…¥çš„æ˜¯å­—ç¬¦ä¸²è€Œéåˆ‡ç‰‡
                top_k=5
            )

            # éªŒè¯candidatesæ ¼å¼ï¼šå¿…é¡»æ˜¯åˆ—è¡¨ï¼Œä¸”å…ƒç´ ä¸ºå«"persona"é”®çš„å­—å…¸
            if not isinstance(candidates, list):
                raise TypeError(f"è§’è‰²æ£€ç´¢è¿”å›éåˆ—è¡¨ç±»å‹ï¼š{type(candidates)}")

            valid_personas = []
            for idx, item in enumerate(candidates):
                if not isinstance(item, dict) or "persona" not in item:
                    print(f"âš ï¸ è¿‡æ»¤æ— æ•ˆè§’è‰²æ•°æ®ï¼ˆç¬¬{idx + 1}ä¸ªï¼‰ï¼š{str(item)[:50]}")
                    continue
                # ç¡®ä¿personaæ˜¯å­—ç¬¦ä¸²
                persona_str = str(item["persona"]).strip()
                if persona_str:
                    valid_personas.append(persona_str)

            if not valid_personas:
                raise ValueError("æœªè·å–åˆ°æœ‰æ•ˆè§’è‰²æ•°æ®ï¼Œæ— æ³•ç»§ç»­å¤„ç†")

            characters = "ï¼›".join(valid_personas)
            print(f"ğŸ“Œ æœ‰æ•ˆè§’è‰²æ•°ï¼š{len(valid_personas)}")

        except Exception as e:
            raise RuntimeError(f"è§’è‰²æ£€ç´¢å¤±è´¥ï¼š{str(e)}") from e

        # 4. Stage1ï¼šç”Ÿæˆè§’è‰²ã€é—®é¢˜ç±»å‹ã€éš¾åº¦
        stage1_prompt = emd_stage1.format(
            passage=passage_str,
            characters=characters
        )
        stage1_resp = llm_client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": stage1_prompt}
            ],
            extra_body={"enable_thinking": False},
            temperature=0.1,
            stream=False
        )

        # éªŒè¯Stage1è¿”å›æ˜¯å¦ä¸ºJSON
        stage1_content = stage1_resp.choices[0].message.content.strip()
        try:
            stage1_result = json.loads(stage1_content)
        except json.JSONDecodeError as e:
            raise ValueError(f"Stage1è¿”å›éJSONæ ¼å¼ï¼š{stage1_content[:100]}") from e

        # æå–Stage1ç»“æœï¼ˆéªŒè¯å¿…è¦å­—æ®µï¼‰
        required_fields = ["Characters", "Question_Type", "Difficulty"]
        for field in required_fields:
            if field not in stage1_result:
                raise KeyError(f"Stage1ç»“æœç¼ºå°‘å¿…è¦å­—æ®µï¼š{field}")

        character = str(stage1_result["Characters"]).strip()
        question_type = str(stage1_result["Question_Type"]).strip()
        difficulty = str(stage1_result["Difficulty"]).strip()

        # 5. Stage2ï¼šç”ŸæˆQuery
        stage2_prompt = emd_stage2.format(
            passage=doc_contents,
            character=character,
            type=question_type,
            difficulty=difficulty
        )
        stage2_resp = llm_client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": stage2_prompt}
            ],
            extra_body={"enable_thinking": False},
            temperature=0.1,
            stream=False
        )

        # å¤„ç†Stage2ç»“æœ
        generated_query = stage2_resp.choices[0].message.content.strip()
        try:
            query_json = json.loads(generated_query)
            if isinstance(query_json, dict):
                final_query = str(query_json.get("Generated_Query", generated_query)).strip()
            else:
                # å¦‚æœè§£æç»“æœæ˜¯listæˆ–strï¼Œç›´æ¥å½“æˆquery
                final_query = str(query_json).strip()
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯åˆæ³•JSONï¼Œå°±ç›´æ¥åŸæ ·ä½¿ç”¨
            final_query = generated_query.strip()

        # æ„å»ºæœ€ç»ˆç»“æœ
        final_doc = {
            "id": doc["id"],
            "contents": doc_contents,
            **({"metadata": doc["metadata"]} if "metadata" in doc and isinstance(doc["metadata"], dict) else {}),
            "character": character,
            "question_type": question_type,
            "difficulty": difficulty,
            "query": final_query
        }
        final_doc["_process_status"] = "success"
        print(f"âœ… æ–‡æ¡£[{doc['id'][:8]}...]å¤„ç†æˆåŠŸ")
        return final_doc

    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)[:50]}"
        print(f"âŒ æ–‡æ¡£[{doc['id'][:8]}...]å¤„ç†å¤±è´¥ï¼š{error_msg}")
        return {"_process_status": "failed", "id": doc["id"]}


def main():
    try:
        print("=" * 60)
        print("ğŸš€ å¼€å§‹æ–‡æ¡£ä¸²è¡Œå¤„ç†æµç¨‹ï¼ˆä¿®å¤æ ¼å¼é”™è¯¯ï¼‰")
        print("=" * 60)

        # 1. åˆå§‹åŒ–èµ„æº
        print("\n1. åˆå§‹åŒ–ä¾èµ–èµ„æº")
        llm_client = init_llm_client()
        persona_retriever = PersonaRetriever(PERSONA_INDEX_DIR)
        print("âœ… æ‰€æœ‰ä¾èµ–èµ„æºåˆå§‹åŒ–å®Œæˆ")

        # 2. è¯»å–è¾“å…¥æ–‡æ¡£
        print("\n2. è¯»å–è¾“å…¥æ–‡æ¡£")
        input_docs = load_jsonl(INPUT_JSONL_PATH)
        if not input_docs:
            print("âš ï¸ æ— æœ‰æ•ˆæ–‡æ¡£ï¼Œç¨‹åºé€€å‡º")
            return

        # 3. ä¸²è¡Œå¤„ç†æ–‡æ¡£
        print(f"\n3. å¼€å§‹ä¸²è¡Œå¤„ç†ï¼ˆå…±{len(input_docs)}ä¸ªæ–‡æ¡£ï¼‰")
        success_count = 0
        failed_count = 0

        for doc in tqdm(input_docs, desc="ğŸ“Š ä¸²è¡Œå¤„ç†è¿›åº¦"):
            result = process_single_doc(doc, llm_client, persona_retriever)
            if result["_process_status"] == "success":
                del result["_process_status"]
                append_single_doc_to_jsonl(result, OUTPUT_JSONL_PATH)
                success_count += 1
            else:
                failed_count += 1
            time.sleep(0.1)  # é¿å…APIè¯·æ±‚è¿‡äºå¯†é›†

        # 4. è¾“å‡ºç»Ÿè®¡
        print("\n4. å¤„ç†ç»Ÿè®¡æŠ¥å‘Š")
        total_count = len(input_docs)
        print(f"ğŸ“‹ ç»Ÿè®¡ç»“æœï¼š")
        print(f"   - æ€»å¤„ç†æ–‡æ¡£æ•°ï¼š{total_count}")
        print(f"   - æˆåŠŸæ•°ï¼š{success_count}ï¼ˆ{round(success_count / total_count * 100, 1)}%ï¼‰")
        print(f"   - å¤±è´¥æ•°ï¼š{failed_count}ï¼ˆ{round(failed_count / total_count * 100, 1)}%ï¼‰")
        print(f"   - è¾“å‡ºæ–‡ä»¶ï¼š{OUTPUT_JSONL_PATH}")

        print("\n" + "=" * 60)
        print("ğŸ‰ ä¸²è¡Œå¤„ç†æµç¨‹å®Œæˆ")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ ç¨‹åºå…¨å±€å¼‚å¸¸ï¼š{str(e)}")
        traceback.print_exc()
        print("=" * 60)


if __name__ == "__main__":
    # é…ç½®å‚æ•°
    INPUT_JSONL_PATH = "./datasets/OmniEval-Corpus/all_data_clean.jsonl"
    OUTPUT_JSONL_PATH = "./datasets/OmniEval-Corpus/all_data_clean_query.jsonl"
    PERSONA_INDEX_DIR = "./datasets/persona-hub/finance_persona_index"
    LLM_MODEL = "qwen3-30b-a3b-instruct-2507"#"qwen3-30b-a3b"
    SYSTEM_PROMPT = "ä½ æ˜¯é‡‘èé¢†åŸŸçš„ä¸“ä¸šåˆ†æåŠ©æ‰‹"

    main()
    # file = load_jsonl("../../datasets/OmniEval-Corpus/all_data_clean.jsonl")
    # print(file)
